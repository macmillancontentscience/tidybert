% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tidy_output.R
\name{.make_token_map}
\alias{.make_token_map}
\title{Make Token Map}
\usage{
.make_token_map(tokenized)
}
\arguments{
\item{tokenized}{The raw output from \code{torchtransformers::tokenize_bert} with \code{simplify = FALSE}.}
}
\value{
A data frame of the input tokens, with explicit index columns.
}
\description{
Given a list of input token sequences, construct a data frame with explicit
index columns. Later this can be joined onto the indexed outputs to add the
actual token and segment columns to the tidy data frames.
}
\keyword{internal}
